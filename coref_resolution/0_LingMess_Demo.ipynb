{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# LingMess: Linguistically Informed Multi Expert Scorers for Coreference Resolution\n",
        "This notebook is the official Demo of the paper [\"LingMess: Linguistically Informed Multi Expert Scorers for Coreference Resolution\"](https://arxiv.org/abs/2205.12644).\n"
      ],
      "metadata": {
        "id": "R22r1NPS1egU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clone the code repository"
      ],
      "metadata": {
        "id": "woaQaI-21ySV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iS1vKuqCdYud",
        "outputId": "37d64859-ba62-411c-af74-d3f23bf18b53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'lingmess-coref'...\n",
            "remote: Enumerating objects: 396, done.\u001b[K\n",
            "remote: Counting objects: 100% (158/158), done.\u001b[K\n",
            "remote: Compressing objects: 100% (111/111), done.\u001b[K\n",
            "remote: Total 396 (delta 98), reused 102 (delta 47), pack-reused 238\u001b[K\n",
            "Receiving objects: 100% (396/396), 97.83 KiB | 7.52 MiB/s, done.\n",
            "Resolving deltas: 100% (251/251), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/shon-otmazgin/lingmess-coref.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install requirements"
      ],
      "metadata": {
        "id": "mhp4SodY17GB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version # make sure to use python 3.7, otherwise install it."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZACMnCOdiLx",
        "outputId": "ad9b400e-06d0-47e5-ca4f-a377b4588b99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.7.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd lingmess-coref/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXP9E3gkv3xQ",
        "outputId": "17f2aaab-ccef-436c-cba3-c4010a260470"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/lingmess-coref\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sDrfLBbD0P70",
        "outputId": "4d46c04f-4199-48d5-a411-4c8db1c749cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en-core-web-sm@ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.0.0/en_core_web_sm-3.0.0-py3-none-any.whl\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.0.0/en_core_web_sm-3.0.0-py3-none-any.whl (13.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 13.7 MB 15.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm==4.64.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (4.64.0)\n",
            "Requirement already satisfied: numpy==1.21.6 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (1.21.6)\n",
            "Collecting scipy==1.7.3\n",
            "  Downloading scipy-1.7.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 38.1 MB 367 kB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas==1.3.5 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (1.3.5)\n",
            "Collecting spacy==3.0.6\n",
            "  Downloading spacy-3.0.6-cp37-cp37m-manylinux2014_x86_64.whl (12.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.8 MB 31.4 MB/s \n",
            "\u001b[?25hCollecting torch==1.10.0\n",
            "  Downloading torch-1.10.0-cp37-cp37m-manylinux1_x86_64.whl (881.9 MB)\n",
            "\u001b[K     |██████████████████████████████▎ | 834.1 MB 1.2 MB/s eta 0:00:40tcmalloc: large alloc 1147494400 bytes == 0x3a19e000 @  0x7fc32b989615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n",
            "\u001b[K     |████████████████████████████████| 881.9 MB 19 kB/s \n",
            "\u001b[?25hCollecting sentencepiece==0.1.96\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 62.0 MB/s \n",
            "\u001b[?25hCollecting transformers==4.11.3\n",
            "  Downloading transformers-4.11.3-py3-none-any.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 53.8 MB/s \n",
            "\u001b[?25hCollecting datasets==2.1.0\n",
            "  Downloading datasets-2.1.0-py3-none-any.whl (325 kB)\n",
            "\u001b[K     |████████████████████████████████| 325 kB 73.2 MB/s \n",
            "\u001b[?25hCollecting wandb==0.12.15\n",
            "  Downloading wandb-0.12.15-py2.py3-none-any.whl (1.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 48.7 MB/s \n",
            "\u001b[?25hCollecting protobuf==3.20.1\n",
            "  Downloading protobuf-3.20.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 62.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.3.5->-r requirements.txt (line 4)) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.3.5->-r requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.0.6->-r requirements.txt (line 5)) (0.4.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==3.0.6->-r requirements.txt (line 5)) (2.0.6)\n",
            "Collecting srsly<3.0.0,>=2.4.1\n",
            "  Downloading srsly-2.4.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (457 kB)\n",
            "\u001b[K     |████████████████████████████████| 457 kB 73.1 MB/s \n",
            "\u001b[?25hCollecting catalogue<2.1.0,>=2.0.3\n",
            "  Downloading catalogue-2.0.7-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.0.6->-r requirements.txt (line 5)) (21.3)\n",
            "Collecting typer<0.4.0,>=0.3.0\n",
            "  Downloading typer-0.3.2-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy==3.0.6->-r requirements.txt (line 5)) (0.9.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy==3.0.6->-r requirements.txt (line 5)) (2.11.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==3.0.6->-r requirements.txt (line 5)) (3.0.6)\n",
            "Collecting spacy-legacy<3.1.0,>=3.0.4\n",
            "  Downloading spacy_legacy-3.0.9-py2.py3-none-any.whl (20 kB)\n",
            "Collecting typing-extensions<4.0.0.0,>=3.7.4\n",
            "  Downloading typing_extensions-3.10.0.2-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.0.6->-r requirements.txt (line 5)) (2.23.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy==3.0.6->-r requirements.txt (line 5)) (1.0.7)\n",
            "Collecting pathy>=0.3.5\n",
            "  Downloading pathy-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 1.8 MB/s \n",
            "\u001b[?25hCollecting pydantic<1.8.0,>=1.7.1\n",
            "  Downloading pydantic-1.7.4-cp37-cp37m-manylinux2014_x86_64.whl (9.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.1 MB 47.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy==3.0.6->-r requirements.txt (line 5)) (57.4.0)\n",
            "Collecting thinc<8.1.0,>=8.0.3\n",
            "  Downloading thinc-8.0.17-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (660 kB)\n",
            "\u001b[K     |████████████████████████████████| 660 kB 73.8 MB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 48.5 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 70.8 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub>=0.0.17\n",
            "  Downloading huggingface_hub-0.7.0-py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 6.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.11.3->-r requirements.txt (line 9)) (3.7.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.11.3->-r requirements.txt (line 9)) (4.11.4)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 67.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.11.3->-r requirements.txt (line 9)) (2022.6.2)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 70.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets==2.1.0->-r requirements.txt (line 10)) (0.70.13)\n",
            "Collecting fsspec[http]>=2021.05.0\n",
            "  Downloading fsspec-2022.5.0-py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 77.1 MB/s \n",
            "\u001b[?25hCollecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 54.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets==2.1.0->-r requirements.txt (line 10)) (0.3.5.1)\n",
            "Requirement already satisfied: pyarrow>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets==2.1.0->-r requirements.txt (line 10)) (6.0.1)\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.2.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29 kB)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb==0.12.15->-r requirements.txt (line 11)) (1.15.0)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.9-py3-none-any.whl (9.4 kB)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb==0.12.15->-r requirements.txt (line 11)) (7.1.2)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.5.12-py2.py3-none-any.whl (145 kB)\n",
            "\u001b[K     |████████████████████████████████| 145 kB 67.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb==0.12.15->-r requirements.txt (line 11)) (2.3)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 76.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb==0.12.15->-r requirements.txt (line 11)) (5.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.3->spacy==3.0.6->-r requirements.txt (line 5)) (3.8.0)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 2.1 MB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy==3.0.6->-r requirements.txt (line 5)) (3.0.9)\n",
            "Collecting smart-open<6.0.0,>=5.0.0\n",
            "  Downloading smart_open-5.2.1-py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 7.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.0.6->-r requirements.txt (line 5)) (2022.5.18.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.0.6->-r requirements.txt (line 5)) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.0.6->-r requirements.txt (line 5)) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.0.6->-r requirements.txt (line 5)) (3.0.4)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 73.8 MB/s \n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 59.4 MB/s \n",
            "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 4.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets==2.1.0->-r requirements.txt (line 10)) (2.0.12)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets==2.1.0->-r requirements.txt (line 10)) (21.4.0)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 75.6 MB/s \n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy==3.0.6->-r requirements.txt (line 5)) (2.0.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.11.3->-r requirements.txt (line 9)) (1.1.0)\n",
            "Building wheels for collected packages: pathtools, sacremoses\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=9020da2b337c459e93fd5ecbfa424e6f83e7373a2883f11db9375aa3392a70fd\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=39572fabfecfc3ca0888d58ba0a198e330e0827b4417ca846015c4469a7a29ae\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "Successfully built pathtools sacremoses\n",
            "Installing collected packages: typing-extensions, multidict, frozenlist, catalogue, yarl, urllib3, typer, srsly, smmap, smart-open, pydantic, asynctest, async-timeout, aiosignal, thinc, spacy-legacy, pyyaml, pathy, gitdb, fsspec, aiohttp, xxhash, tokenizers, spacy, shortuuid, setproctitle, sentry-sdk, sacremoses, responses, protobuf, pathtools, huggingface-hub, GitPython, docker-pycreds, wandb, transformers, torch, sentencepiece, scipy, en-core-web-sm, datasets\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 4.2.0\n",
            "    Uninstalling typing-extensions-4.2.0:\n",
            "      Successfully uninstalled typing-extensions-4.2.0\n",
            "  Attempting uninstall: catalogue\n",
            "    Found existing installation: catalogue 1.0.0\n",
            "    Uninstalling catalogue-1.0.0:\n",
            "      Successfully uninstalled catalogue-1.0.0\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: srsly\n",
            "    Found existing installation: srsly 1.0.5\n",
            "    Uninstalling srsly-1.0.5:\n",
            "      Successfully uninstalled srsly-1.0.5\n",
            "  Attempting uninstall: smart-open\n",
            "    Found existing installation: smart-open 6.0.0\n",
            "    Uninstalling smart-open-6.0.0:\n",
            "      Successfully uninstalled smart-open-6.0.0\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 2.2.4\n",
            "    Uninstalling spacy-2.2.4:\n",
            "      Successfully uninstalled spacy-2.2.4\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.17.3\n",
            "    Uninstalling protobuf-3.17.3:\n",
            "      Successfully uninstalled protobuf-3.17.3\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.11.0+cu113\n",
            "    Uninstalling torch-1.11.0+cu113:\n",
            "      Successfully uninstalled torch-1.11.0+cu113\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "  Attempting uninstall: en-core-web-sm\n",
            "    Found existing installation: en-core-web-sm 2.2.5\n",
            "    Uninstalling en-core-web-sm-2.2.5:\n",
            "      Successfully uninstalled en-core-web-sm-2.2.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.12.0+cu113 requires torch==1.11.0, but you have torch 1.10.0 which is incompatible.\n",
            "torchtext 0.12.0 requires torch==1.11.0, but you have torch 1.10.0 which is incompatible.\n",
            "torchaudio 0.11.0+cu113 requires torch==1.11.0, but you have torch 1.10.0 which is incompatible.\n",
            "tensorflow 2.8.2+zzzcolab20220527125636 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed GitPython-3.1.27 aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 catalogue-2.0.7 datasets-2.1.0 docker-pycreds-0.4.0 en-core-web-sm-3.0.0 frozenlist-1.3.0 fsspec-2022.5.0 gitdb-4.0.9 huggingface-hub-0.7.0 multidict-6.0.2 pathtools-0.1.2 pathy-0.6.1 protobuf-3.20.1 pydantic-1.7.4 pyyaml-6.0 responses-0.18.0 sacremoses-0.0.53 scipy-1.7.3 sentencepiece-0.1.96 sentry-sdk-1.5.12 setproctitle-1.2.3 shortuuid-1.0.9 smart-open-5.2.1 smmap-5.0.0 spacy-3.0.6 spacy-legacy-3.0.9 srsly-2.4.3 thinc-8.0.17 tokenizers-0.10.3 torch-1.10.0 transformers-4.11.3 typer-0.3.2 typing-extensions-3.10.0.2 urllib3-1.25.11 wandb-0.12.15 xxhash-3.0.0 yarl-1.7.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google",
                  "typing_extensions"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are some incompatible ^^^ but they for packages we not using so we can continue."
      ],
      "metadata": {
        "id": "HS8S8FWL2UKq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare your custom data for Inference"
      ],
      "metadata": {
        "id": "e9-lTqJb2AKA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import uuid\n",
        "\n",
        "examples = [\n",
        "        {'doc_key': uuid.uuid4().hex, 'text': 'The man tried to put the boot on his foot but it was too small.'},\n",
        "        {'doc_key': uuid.uuid4().hex, 'text': 'Some apologizing was needed in the relationship after the argument because it is soothing.'}\n",
        "    ]\n",
        "with open('toy_data_raw.jsonlines', 'w') as f:\n",
        "    for doc in examples:\n",
        "        f.write(json.dumps(doc) + \"\\n\")"
      ],
      "metadata": {
        "id": "wB35Zlf2mcGM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference"
      ],
      "metadata": {
        "id": "Vu1vmX2a2e8J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python run.py \\\n",
        "        --output_file=predictions.jsonlines \\\n",
        "        --model_name_or_path=biu-nlp/lingmess-coref \\\n",
        "        --test_file=toy_data_raw.jsonlines \\\n",
        "        --eval_split=test \\\n",
        "        --max_tokens_in_batch=15000 \\\n",
        "        --device=cuda:0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFR8VeHmAkvZ",
        "outputId": "e331a0b9-6488-42a6-95c1-a0481bcbac6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "06/15/2022 16:13:16 - INFO - __main__ -   missing_keys: []\n",
            "06/15/2022 16:13:16 - INFO - __main__ -   unexpected_keys: []\n",
            "06/15/2022 16:13:16 - INFO - __main__ -   mismatched_keys: []\n",
            "06/15/2022 16:13:16 - INFO - __main__ -   error_msgs: []\n",
            "06/15/2022 16:13:16 - INFO - __main__ -   Parameters: 590.0M, Transformer: 434.6M, Head: 155.4M\n",
            "06/15/2022 16:13:16 - INFO - coref_dataset -   Creating dataset for {'train': None, 'dev': None, 'test': 'toy_data_raw.jsonlines'}\n",
            "06/15/2022 16:13:18 - INFO - util -   Tokenize documents using Spacy...\n",
            "100% 2/2 [00:00<00:00, 81.54it/s]\n",
            "06/15/2022 16:13:18 - INFO - coref_dataset -   Tokenize documents...\n",
            "06/15/2022 16:13:18 - WARNING - datasets.fingerprint -   Parameter 'function'=<function encode at 0x7fc4bd45acb0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n",
            "100% 2/2 [00:00<00:00, 125.83ex/s]\n",
            "06/15/2022 16:13:18 - INFO - eval -   ***** Running Inference on test split  *****\n",
            "06/15/2022 16:13:18 - INFO - eval -     Examples number: 2\n",
            "Inference: 100% 2/2 [00:00<00:00,  4.71it/s]\n",
            "06/15/2022 16:13:19 - INFO - util -   Predicted clusters at: predictions.jsonlines\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resolve the clusters"
      ],
      "metadata": {
        "id": "w8NlU0TGW433"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "predicted_docs = []\n",
        "with open('predictions.jsonlines', 'r') as f:\n",
        "    for line in f:\n",
        "        predicted_docs.append(json.loads(line))\n",
        "\n",
        "for i, doc in enumerate(predicted_docs):\n",
        "    tokens = doc['tokens']\n",
        "    predicted_clusters = doc['clusters']\n",
        "    doc_key = doc['doc_key']\n",
        "    print(f\"##### doc_key: {doc_key}\")\n",
        "\n",
        "    for cluster in predicted_clusters:\n",
        "        text_cluster = []\n",
        "        for start, end in cluster:\n",
        "            text_cluster.append(tokens[start:end+1])\n",
        "        print(text_cluster)\n",
        "    print(\"###########################\")\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxpP_55-Iaw4",
        "outputId": "b4799113-5184-47d8-e31b-6c74b68e4287"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##### doc_key: 300b22c2baa447aea33e34b2a0bcbfe3\n",
            "[['The', 'man'], ['his']]\n",
            "[['the', 'boot'], ['it']]\n",
            "###########################\n",
            "\n",
            "##### doc_key: 022810dea7c04365aff96fed73f3dd23\n",
            "[['Some', 'apologizing'], ['it']]\n",
            "###########################\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yhfQs-lfJBGp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}